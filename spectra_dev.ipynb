{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af079033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Any, Iterable\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdc08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_audio = \"./test_data/karma police.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39161d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 2)\n"
     ]
    }
   ],
   "source": [
    "class AudioIO:\n",
    "    backend: str = \"pydub\"\n",
    " \n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        target_sample_rate: Optional[int] = 44100,\n",
    "        mono: Optional[bool] = True,\n",
    "        normalize: Optional[bool] = True,\n",
    "        chunk_size: Optional[int] = 1024,\n",
    "        hop_size: Optional[int] = 512,\n",
    "        dtype: Optional[Any] = np.float32,\n",
    "    ):\n",
    "        assert os.path.exists(path)\n",
    "        self.path = path\n",
    "        self.sample_rate = target_sample_rate\n",
    "        self.mono = mono\n",
    "        self.normalize = normalize\n",
    "        self.chunk_size = chunk_size\n",
    "        self.hop_size = hop_size\n",
    "        self.dtype = dtype\n",
    "        self.sample_length = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sample_length - self.chunk_size // self.hop_size\n",
    " \n",
    "    def __normalize(self, samples):\n",
    "        if not isinstance(samples, np.ndarray):\n",
    "            samples = np.asarray(samples, self.dtype)\n",
    "        samples /= np.max(np.abs(samples))\n",
    "        return samples\n",
    "    \n",
    "    def _sample_chunk(self, samples, chunk_index):\n",
    "        start = chunk_index * self.chunk_size\n",
    "        end = (start + self.chunk_size)\n",
    "        chunk = samples[start:end]\n",
    "        return np.asarray(np.array_split(chunk, self.hop_size))\n",
    " \n",
    "    def read(self, chunk_index: Optional[int]=None, verbose=False, truncate: Optional[int]=None):\n",
    "        audio: AudioSegment = AudioSegment.from_file(self.path, format=\"wav\")\n",
    "        if self.mono:\n",
    "            audio = audio.set_channels(1).set_frame_rate(self.sample_rate)\n",
    "            samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "        else:\n",
    "            audio = audio.set_frame_rate(self.sample_rate)\n",
    "            audio = audio.split_to_mono()\n",
    "            left = audio[0].get_array_of_samples()\n",
    "            right = audio[1].get_array_of_samples()\n",
    "            # audio = audio.get_array_of_samples()\n",
    "            samples = np.array([left, right]).astype(np.float32)\n",
    "        if self.normalize:\n",
    "            samples = self.__normalize(samples)\n",
    "\n",
    "        self.sample_length = len(samples)\n",
    "        if not chunk_index is None and isinstance(chunk_index, int):\n",
    "            samples = self._sample_chunk(samples, chunk_index)\n",
    " \n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Sample shape: {samples.shape}, Audio type: {type(audio)}, Num Channels: {self.num_channels}, Sample Rate: {self.sample_rate}\"\n",
    "            )\n",
    "        if truncate is None:\n",
    "            return samples, self.sample_rate\n",
    "        elif not self.mono:\n",
    "            return samples[:, :truncate], self.sample_rate\n",
    "        else:\n",
    "            return samples[:truncate], self.sample_rate\n",
    "        \n",
    "reader = AudioIO(path_to_audio, mono=True)\n",
    "audio, sample_rate = reader.read(chunk_index=1)\n",
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7030b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 512 but size of corresponding boolean axis is 513",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspectra\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Real1DLogFFT\n\u001b[32m      3\u001b[39m fft_op = Real1DLogFFT(sample_rate)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m fft_frames, freqs = \u001b[43mfft_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_transforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(fft_frames.shape, freqs.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/personal/Spectra/spectra/fft.py:224\u001b[39m, in \u001b[36mReal1DLogFFT.__call__\u001b[39m\u001b[34m(self, x, apply_transforms, transform_step, dim_reduction, return_freq_edges, **kw)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# get log transformed frames\u001b[39;00m\n\u001b[32m    223\u001b[39m log_edges, freqs = \u001b[38;5;28mself\u001b[39m._get_logspace_freqs(freqs)\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m fft_frames = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate_log_bins\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transform_step == \u001b[33m\"\u001b[39m\u001b[33mafter\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m apply_transforms:\n\u001b[32m    227\u001b[39m     fft_frames = \u001b[38;5;28mself\u001b[39m.apply(x, dim_reduction)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/personal/Spectra/spectra/fft.py:186\u001b[39m, in \u001b[36mReal1DLogFFT.aggregate_log_bins\u001b[39m\u001b[34m(self, fft_frame, log_bin_indices, normalize)\u001b[39m\n\u001b[32m    184\u001b[39m     bin_mask = log_bin_indices == i\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(bin_mask):\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         log_magnitudes[i] = np.mean(\u001b[43mfft_frame\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbin_mask\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m    188\u001b[39m     log_magnitudes /= np.max(log_magnitudes)\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 0; size of axis is 512 but size of corresponding boolean axis is 513"
     ]
    }
   ],
   "source": [
    "from spectra.fft import Real1DLogFFT\n",
    "\n",
    "fft_op = Real1DLogFFT(sample_rate)\n",
    "\n",
    "fft_frames, freqs = fft_op(audio, apply_transforms=False)\n",
    "print(fft_frames.shape, freqs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
